---
layout: project
permalink: /:title/
date: 2017-03-28

meta:
  keywords: ""

categories:
  - "project"
  - "software"
  - "research"

project:
  title: "WaveTrace"
  url: "https://chiplay.acm.org/2019/"
  logo: "/assets/images/wavetrace/logo.png"
  tech: "Placeholder"

images:
  - image:
    url: "/assets/images/wavetrace/1.jpg"
    title: "The Domestic Widgets toolkit"
    alt: "Cardboard pieces, electronic components, a Google Home and an assembled Domestic Widget"
  - image:
    url: "/assets/images/wavetrace/1.jpg"
    title: "The Domestic Widgets toolkit"
    alt: "Cardboard pieces, electronic components, a Google Home and an assembled Domestic Widget"
  - image:
    type: "video"
    url: "7Uc9FF8yaVQ"
    alt: "Explainer Video, without voice-over, of the WaveTrace technique."


    Media files: https://chi2020.acm.org/press-and-media/chi-2020-logo/

---

<p>
WaveTrace is a tracking technique which allows you to interact with systems by mimicking the movement of its 'options'. When activated, your Wi-Fi enabled smartwatch will calculate if your wrist is moving similarly to any of the presented options, and if so, will activate that option. This allows you to interact with numerous devices and services without the use of optical sensors (i.e. cameras), or the need to remember any gesture whatsoever. After performance testing in a lab-based setting, four prototypes were created for four different scenarios to study its real-world usefulness for: smart home control, television control, classroom participation, and individual interaction with public displays.
</p>
<h2 class="h2">Technology</h2>
<p>
The system builds upon a prototype build for <u><a href="{{ "/smoothmoves" | prepend: baseurl }}">SmoothMoves</a></u>, and utilises an Inertial Measurement Unit (IMU) built into most smart watches. With a flick of the wrist, the WaveTrace Android smartwatch app requests devices on the local network to display their targets such that their targets movement's do not correlate. Wrist movement data is then send over UDP to a central hub (laptop), via a bluetooth connected smart phone, over Wi-Fi, which then continuously performs a correlation between this movement data, and - upon selection - controls the device showing the correlated target. A newer version of this prototype used an Android Wear 2.0 smartwatch, eliminating the need for a smart phone.
</p>
<h2 class="h2">Contribution</h2>
<p>
As part of my Master Thesis, I fully developed the software for this specific interaction technique, and studied its performance. Similarly, I built upon this with four software prototypes and user studies and analysed the results. After my MSc, I developed this research prototype into a <u><a href="{{ "/motionlights" | prepend: baseurl }}"> product family of three lights</a></u>.
</p>
